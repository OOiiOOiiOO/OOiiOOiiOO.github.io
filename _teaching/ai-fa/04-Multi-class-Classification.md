---
title: "مقدمه‌ای بر شبکه‌های عصبی مصنوعی"
collection: teaching
permalink: /teaching/ai-fa/multi-class
course: "هوش مصنوعی"
order: 2
mathjax: true
use_math: true
layout: course
lang: fa
alt_lang: en
alt_url: /teaching/ai/multi-class
---

# 📘 مقدمه‌ای بر شبکه‌های عصبی مصنوعی (ANN)

شبکه‌های عصبی مصنوعی (ANNs) مدل‌های محاسباتی هستند که از ساختار و عملکرد مغز انسان الهام گرفته‌اند.  
این شبکه‌ها از واحدهای به‌هم‌پیوسته‌ای به نام **نورون** تشکیل شده‌اند که در لایه‌ها سازمان‌دهی شده و ورودی‌ها را از طریق **اتصالات وزنی** و **توابع فعال‌سازی** به خروجی تبدیل می‌کنند.  

---

## 🏗 ساختار یک شبکه عصبی

یک ANN پایه معمولاً شامل سه نوع لایه است:  

- **لایه ورودی (Input Layer):** ویژگی‌های ورودی $$(x_1, x_2, \dots, x_n)$$ را دریافت می‌کند.  
- **لایه‌های پنهان (Hidden Layers):** الگوها و نمایش‌های انتزاعی را یاد می‌گیرند.  
- **لایه خروجی (Output Layer):** پیش‌بینی نهایی $$(\hat{y})$$ را تولید می‌کند.  

---

## 🔢 مدل نورون (پرستپترون)

هر نورون مجموع وزنی ورودی‌ها را محاسبه کرده و سپس تابع فعال‌سازی را اعمال می‌کند:  

$$
z = \sum_{i=1}^{n} w_i x_i + b
$$

$$
y = f(z)
$$

**که در آن:**  
- $$x_i$$: ورودی‌ها  
- $$w_i$$: وزن‌ها  
- $$b$$: بایاس  
- $$f$$: تابع فعال‌سازی  

---

## ⚡ توابع فعال‌سازی

توابع فعال‌سازی غیرخطی بودن را وارد شبکه می‌کنند و امکان تقریب توابع پیچیده را فراهم می‌سازند. پرکاربردترین‌ها:  

- **سیگموید (Sigmoid):**  
  $$
  \sigma(z) = \frac{1}{1 + e^{-z}}
  $$

- **تانژانت هیپربولیک (Tanh):**  
  $$
  \tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}
  $$

- **ReLU (واحد خطی اصلاح‌شده):**  
  $$
  f(z) = \max(0, z)
  $$

---

## 🐱🐶 مثال: طبقه‌بندی ساده

فرض کنید می‌خواهیم تشخیص دهیم که یک تصویر **گربه 🐱** است یا **سگ 🐶**.  

- **لایه ورودی:** شدت پیکسل‌های تصویر.  
- **لایه پنهان:** نورون‌هایی که الگوهای ساده مثل لبه‌ها یا اشکال را شناسایی می‌کنند.  
- **لایه خروجی:** ۲ نورون →  
  - نورون ۱ → احتمال (گربه) = $$\hat{y}_1$$  
  - نورون ۲ → احتمال (سگ) = $$\hat{y}_2$$  

اگر خروجی شبکه باشد:  

$$
\hat{y} = [0.3, \ 0.7]
$$

✅ مدل پیش‌بینی می‌کند تصویر **سگ 🐶** است، چون $$\hat{y}_2 = 0.7$$ بیشترین مقدار است.  

---

## 📊 طبقه‌بندی چندکلاسه (گسترش)

برای $$K$$ کلاس، لایه خروجی شامل $$K$$ نورون خواهد بود.  
برای تبدیل نمره‌های خام به احتمال، از **تابع Softmax** استفاده می‌شود:  

$$
\hat{y}_i = \frac{e^{z_i}}{\sum_{j=1}^K e^{z_j}}, \quad i=1,2,\dots,K
$$

**مثال:** طبقه‌بندی تصویر به **گربه 🐱**، **سگ 🐶** یا **خرگوش 🐰**.  

خروجی:  

$$
\hat{y} = [0.1, \ 0.7, \ 0.2]
$$

✅ شبکه پیش‌بینی می‌کند تصویر **سگ 🐶** است، چون $$\hat{y}_2 = 0.7$$.  

---

## 🔧 یادگیری در شبکه‌های عصبی

شبکه با تنظیم وزن‌ها ($$w_i$$) و بایاس ($$b$$) به گونه‌ای آموزش می‌بیند که **تابع خطا (Loss Function)** کمینه شود.  

**مثال: خطای میانگین مربعات (MSE):**  

$$
\mathcal{L} = \frac{1}{N}\sum_{i=1}^N (y_i - \hat{y}_i)^2
$$

گرادیان آن نسبت به وزن‌ها:  

$$
\nabla_w \mathcal{L} = -\frac{2}{N}\sum_{i=1}^N (y_i - \hat{y}_i)\,x_i
$$

---

<div class="lesson-nav" style="display:flex; justify-content:space-between; margin-top:2em;">
  <a class="btn btn--inverse" href="{{ '/teaching/ai-fa/activationfunctions' | relative_url }}">⬅︎ قبلی: توابع فعال‌سازی </a>
  <a class="btn btn--primary" href="{{ '/teaching/ai-fa/anns' | relative_url }}">  مقدمه‌ای بر شبکه‌های عصبی مصنوعی (ANNs)  ➡︎</a>
</div>
