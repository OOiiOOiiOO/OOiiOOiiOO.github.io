---
title: "مقدمه‌ای بر شبکه‌های عصبی مصنوعی (ANNs)"
collection: teaching
permalink: /teaching/ai/annsfa
course: "هوش مصنوعی"
order: 1
mathjax: true
use_math: true
layout: course
lang: fa
---

# مقدمه‌ای بر شبکه‌های عصبی مصنوعی (ANNs)

شبکه‌های عصبی مصنوعی (**Artificial Neural Networks - ANNs**) مدل‌های محاسباتی هستند که از **ساختار و عملکرد مغز انسان** الهام گرفته‌اند.  
هدف آن‌ها شناسایی الگوها، یادگیری از داده‌ها و انجام پیش‌بینی‌هاست.

---

## ساختار یک شبکه عصبی

یک ANN معمولاً از **لایه‌ها** تشکیل شده است:

1. **لایه ورودی (Input Layer)** – دریافت داده خام (ویژگی‌ها).  
2. **لایه‌های پنهان (Hidden Layers)** – پردازش اطلاعات با استفاده از وزن‌ها، بایاس‌ها و توابع فعال‌سازی.  
3. **لایه خروجی (Output Layer)** – تولید خروجی نهایی (مثل برچسب کلاس یا مقدار رگرسیون).

![Neural Network Layers](/images/ai24.jpg)  
*شکل ۱: نمونه‌ای از لایه ورودی، پنهان و خروجی.*

---

## انتشار رو به جلو (Forward Propagation)

داده‌ها از لایه ورودی، از طریق لایه‌های پنهان، به لایه خروجی جریان پیدا می‌کنند.  
هر نورون محاسبه می‌کند:

$$
z = \sum_{i=1}^n w_i x_i + b
$$

و سپس تابع فعال‌سازی اعمال می‌شود:

$$
y = f(z)
$$

که در آن:  
- $$ x_i $$ → مقادیر ورودی  
- $$ w_i $$ → وزن‌های متناظر  
- $$ b $$ → بایاس  
- $$ f $$ → تابع فعال‌سازی  
- $$ y $$ → خروجی نورون  

![Neural Network Layers](/images/ai25.png)  

---

## مثال: یک شبکه عصبی ساده

فرض کنید می‌خواهیم پیش‌بینی کنیم که آیا یک دانشجو **قبول می‌شود یا مردود**، بر اساس **ساعت مطالعه** ($$x_1$$) و **ساعت خواب** ($$x_2$$).

- ورودی‌ها: $$x_1 = 5$$ (ساعت مطالعه)، $$x_2 = 7$$ (ساعت خواب)  
- وزن‌ها: $$w_1 = 0.6$$، $$w_2 = 0.4$$  
- بایاس: $$b = -2$$  
- تابع فعال‌سازی: سیگموید  

**مرحله ۱: محاسبه مجموع وزنی**

$$
z = (w_1 \cdot x_1) + (w_2 \cdot x_2) + b
$$

$$
z = (0.6 \cdot 5) + (0.4 \cdot 7) - 2 = 3 + 2.8 - 2 = 3.8
$$

**مرحله ۲: اعمال تابع فعال‌سازی**

$$
y = \frac{1}{1 + e^{-z}}
$$

$$
y = \frac{1}{1 + e^{-3.8}} \approx 0.978
$$

✅ نتیجه نهایی: $$y \approx 0.98$$ → احتمال قبولی دانشجو بسیار بالاست.

---

## نکات کلیدی

- **وزن‌ها** میزان اهمیت ورودی‌ها را مشخص می‌کنند.  
- **بایاس** آستانه فعال‌سازی را جابه‌جا می‌کند.  
- **توابع فعال‌سازی** غیرخطی بودن را اضافه می‌کنند و امکان یادگیری روابط پیچیده را فراهم می‌سازند.  
- بر اساس **قضیه تقریب جهانی (Universal Approximation Theorem)**، ANNs با لایه‌های پنهان و نورون‌های کافی می‌توانند تقریباً هر تابعی را تقریب بزنند.

![Neuron Functioning](/images/ai26.png)  
*شکل ۲: یک نورون با ورودی‌ها، وزن‌ها، بایاس و تابع فعال‌سازی.*

---

## ✅ خلاصه

- شبکه‌های عصبی مصنوعی از مغز الهام گرفته‌اند ولی ساده‌سازی شده‌اند.  
- آن‌ها از **لایه‌هایی از نورون‌ها** با وزن‌ها، بایاس‌ها و توابع فعال‌سازی تشکیل شده‌اند.  
- در انتشار رو به جلو، داده از شبکه عبور کرده و خروجی پیش‌بینی می‌شود.  
- با آموزش، شبکه وزن‌ها را طوری تنظیم می‌کند که خطای پیش‌بینی به حداقل برسد.  

---

<div class="lesson-nav" style="display:flex; justify-content:space-between; margin-top:2em;">
  <a class="btn btn--inverse" href="{{ '/teaching/ai/multi-class-fa' | relative_url }}">⬅︎ قبلی: طبقه‌بندی چندکلاسه </a>
  <a class="btn btn--primary" href="{{ '/teaching/ai/hw1-fa' | relative_url }}">بعدی: تکلیف ۱ ➡︎</a>
</div>
