---
title: "ุชูุงุจุน ูุนุงูโุณุงุฒ ุฏุฑ ุดุจฺฉูโูุง ุนุตุจ"
collection: teaching
permalink: /teaching/ai/activation-functions
course: "ููุด ูุตููุน"
order: 1
mathjax: true
use_math: true
layout: course
---

# ุชูุงุจุน ูุนุงูโุณุงุฒ

ุดุจฺฉูโูุง ุนุตุจ ูุตููุน (ANNs) ูุฏุฑุชููุฏ ูุณุชูุฏ ุฒุฑุง ูโุชูุงููุฏ **ุชูุงุจุน ุบุฑุฎุท** ุฑุง ุชูุฑุจ ุจุฒููุฏ.  
ุงฺฏุฑ ุชูุงุจุน ูุนุงูโุณุงุฒ ูุฌูุฏ ูุฏุงุดุชู ุจุงุดูุฏุ ุญุช ุงฺฏุฑ ฺูุฏู ูุงู ุฑู ูู ูุฑุงุฑ ุฏููุ ุดุจฺฉู ููฺูุงู ูุนุงุฏู ฺฉ **ุชุจุฏู ุฎุท ูุงุญุฏ** ุฎูุงูุฏ ุจูุฏ. ุงู ุนู ุดุจฺฉู ููโุชูุงูุฏ ุฑูุงุจุท ูพฺุฏู ูุซู ุงูฺฏููุง ุชุตูุฑุ ุณฺฏูุงูโูุง ุตูุช ุง ูุฑุฒูุง ุชุตููโฺฏุฑ ุฑุง ูุฏู ฺฉูุฏ.

ุชูุงุจุน ูุนุงูโุณุงุฒ ุจุง ุงูุฒูุฏู **ุบุฑุฎุท ุจูุฏู** ุจู ุดุจฺฉูุ ุงูฺฉุงู ุงุฏฺฏุฑ ูฺฏุงุดุชโูุง ุจุณุงุฑ ูพฺุฏู ุงุฒ ูุฑูุฏ ุจู ุฎุฑูุฌ ุฑุง ูุฑุงูู ูโฺฉููุฏ. ูุฑ ุชุงุจุน ูฺฺฏโูุงุ ูุฒุงุง ู ูุนุงุจ ุฎุงุต ุฎูุฏ ุฑุง ุฏุงุฑุฏ.

---

## ฑ. ุชุงุจุน ุฎุท (Linear)

**ูุฑููู:**

$$
f(x) = x
$$

**ูุซุงู:**

$$
f(2.5) = 2.5
$$

**ูุฒุงุง:**
- ุจุณุงุฑ ุณุงุฏูุ ุจุฏูู ูุดฺฉู ฺฏุฑุงุฏุงู ูุญู (Vanishing Gradient).  

**ูุนุงุจ:**
- ุชูุงูุง ูุฏูโุณุงุฒ ุฏุงุฏูโูุง ุบุฑุฎุท ุฑุง ูุฏุงุฑุฏ.  
- ุจุฑุง ูุงูโูุง ูพููุงู ุนูู ุจโูุงุฏู ุงุณุช.  

![General Formula](/images/ai5.avif)

---

## ฒ. ุชุงุจุน ุณฺฏููุฏ (Sigmoid)

**ูุฑููู:**

$$
f(x) = \frac{1}{1 + e^{-x}}
$$

**ูุซุงูโูุง:**

$$
f(0) = 0.5
$$

$$
f(2) \approx 0.88
$$

$$
f(-3) \approx 0.047
$$

**ูุฒุงุง:**
- ููุญู ุตุงู ู ูุงุจู ูุดุชูโฺฏุฑ ุฏุฑ ููู ููุงุท.  
- ุชูุณุฑ ุงุญุชูุงูุงุช ุฎูุจ.  

**ูุนุงุจ:**
- ูุดฺฉู ฺฏุฑุงุฏุงู ูุญู ุจุฑุง ููุงุฏุฑ ุจุฒุฑฺฏ $$x$$.  
- ุฎุฑูุฌ ุตูุฑูุฑฺฉุฒ (Zero-centered) ูุณุช.  

![General Formula](/images/ai11.ppm)

---

## ณ. ุชุงูฺุงูุช ููพุฑุจููฺฉ (Tanh)

**ูุฑููู:**

$$
f(x) = \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
$$

**ูุซุงูโูุง:**

$$
f(0) = 0
$$

$$
f(1) \approx 0.76
$$

$$
f(-2) \approx -0.96
$$

**ูุฒุงุง:**
- ุฎุฑูุฌ ุตูุฑูุฑฺฉุฒ โ ููฺฏุฑุง ุณุฑุนโุชุฑ.  
- ฺฏุฑุงุฏุงู ููโุชุฑ ูุณุจุช ุจู ุณฺฏููุฏ ุจุฑุง $$x$$ูุง ฺฉูฺฺฉ.  

**ูุนุงุจ:**
- ููฺูุงู ูุดฺฉู ฺฏุฑุงุฏุงู ูุญู ุจุฑุง ููุงุฏุฑ ุฎู ุจุฒุฑฺฏ $$x$$ ุฑุง ุฏุงุฑุฏ.  

![General Formula](/images/ai7.png)

---

## ด. ุชุงุจุน ReLU

**ูุฑููู:**

$$
f(x) = \max(0, x)
$$

**ูุซุงูโูุง:**

$$
f(-3) = 0
$$

$$
f(2.5) = 2.5
$$

**ูุฒุงุง:**
- ูุญุงุณุจุงุช ุจุณุงุฑ ฺฉุงุฑุขูุฏ.  
- ฺฉุงูุด ูุดฺฉู ฺฏุฑุงุฏุงู ูุญู.  

**ูุนุงุจ:**
- ูุดฺฉู ยซููุฑูู ูุฑุฏูยป (Dead Neuron).  

![General Formula](/images/ai8.png)

---

## ต. Leaky ReLU

**ูุฑููู:**

$$
f(x) =
\begin{cases}
x & \text{ุงฺฏุฑ } x \geq 0 \\
\alpha x & \text{ุงฺฏุฑ } x < 0
\end{cases}
$$

**ูุซุงู (ุจุง $$\alpha = 0.01$$):**

$$
f(-5) = -0.05, \quad f(3) = 3
$$

**ูุฒุงุง:**
- ุฌููฺฏุฑ ุงุฒ ูุดฺฉู ููุฑูู ูุฑุฏู.  
- ุญูุธ ูุฒุงุง ReLU.  

**ูุนุงุจ:**
- ฺฉู ูพฺุฏูโุชุฑ ุงุฒ ReLU.  

![General Formula](/images/ai9.png)

---

## ถ. ุชุงุจุน Softmax

**ูุฑููู:**

$$
f(x_i) = \frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}}
$$

**ูุซุงู:**

ูุฑูุฏ: $[2.0, 1.0, 0.1]$

$$
f(2.0) = \frac{e^2}{e^2 + e^1 + e^{0.1}} \approx 0.71
$$

$$
f(1.0) \approx 0.26, \quad f(0.1) \approx 0.03
$$

**ูุฒุงุง:**
- ูุฑูุงูโุณุงุฒ ุฎุฑูุฌ ุจู ุงุญุชูุงูโูุง.  
- ุถุฑูุฑ ุจุฑุง ุฏุณุชูโุจูุฏ ฺูุฏฺฉูุงุณู.  

**ูุนุงุจ:**
- ูุญุงุณุจุงุช ุณูฺฏูโุชุฑ.  
- ุญุณุงุณุช ุจู ููุงุฏุฑ ูุฑูุฏ ุจุฒุฑฺฏ.  

![General Formula](/images/ai10.png)

---

## ๐ ุฌุฏูู ููุงุณู

| ุชุงุจุน        | ูุฑููู | ุจุงุฒู | ูุฒุงุง | ูุนุงุจ |
|-------------|-------|------|-------|-------|
| ุฎุท (Linear)     | \(f(x) = x\) | \((-\infty, \infty)\) | ุณุงุฏฺฏุ ููุงุณุจ ุฑฺฏุฑุณูู | ุจุฏูู ุบุฑุฎุท ุจูุฏู |
| ุณฺฏููุฏ (Sigmoid) | \(f(x) = \frac{1}{1+e^{-x}}\) | \([0,1]\) | ุงุญุชูุงูโูุง | ูุดฺฉู ฺฏุฑุงุฏุงู ูุญู |
| ุชุงูฺุงูุช (Tanh)    | \(f(x) = \tanh(x)\) | \([-1,1]\) | ุตูุฑูุฑฺฉุฒ | ฺฏุฑุงุฏุงู ูุญู |
| ReLU        | \(f(x) = \max(0,x)\) | \([0,\infty)\) | ุณุฑุนุ ูพุฑฺฉุงุฑุจุฑุฏ | ููุฑูู ูุฑุฏู |
| Softmax     | \(f(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}\) | \([0,1]\)ุ ุฌูุน=ฑ | ุงุญุชูุงูโูุง ฺูุฏฺฉูุงุณู | ุณูฺฏู ูุญุงุณุจุงุช |

---

# ููุงุณู ููุง

| ุชุงุจุน        | ุจุงุฒู | ูุฒุงุง | ูุนุงุจ |
|-------------|------|-------|-------|
| ุฎุท         | $(-\infty,\infty)$ | ุณุงุฏู | ุจุฏูู ุบุฑุฎุท ุจูุฏู |
| ุณฺฏููุฏ     | $(0,1)$ | ุชูุณุฑ ุงุญุชูุงูุงุช | ฺฏุฑุงุฏุงู ูุญูุ ุตูุฑูุฑฺฉุฒ ูุณุช |
| ุชุงูฺุงูุช     | $(-1,1)$ | ุตูุฑูุฑฺฉุฒุ ููฺฏุฑุง ุจูุชุฑ | ฺฏุฑุงุฏุงู ูุญู |
| ReLU        | $[0,\infty)$ | ุณุฑุน ู ูุญุจูุจ | ููุฑูู ูุฑุฏู |
| Leaky ReLU  | $(-\infty,\infty)$ | ุฑูุน ูุดฺฉู ููุฑูู ูุฑุฏู | ฺฉู ูพฺุฏูโุชุฑ |
| Softmax     | $(0,1)$ | ุงุญุชูุงูโูุงุ ุฌูุน=ฑ | ูพุฑูุฒููุ ูุงูพุงุฏุงุฑ ุจุฑุง ููุงุฏุฑ ุจุฒุฑฺฏ |

---

## โ ุฌูุนโุจูุฏ

- ุชูุงุจุน ูุนุงูโุณุงุฒ **ุบุฑุฎุท ุจูุฏู** ุฑุง ูุงุฑุฏ ุดุจฺฉู ูโฺฉููุฏ.  
- ุงูุชุฎุงุจ ุชุงุจุน ุจุณุชฺฏ ุจู **ููุน ฺฉุงุฑ** (ุทุจููโุจูุฏุ ุฑฺฏุฑุณูู ู ุบุฑู) ุฏุงุฑุฏ.  
- **ReLU** ูพุดโูุฑุถ ุฏุฑ ุงุฏฺฏุฑ ุนูู ุงุณุช.  
- **Softmax** ุจุฑุง ุฎุฑูุฌโูุง ฺูุฏฺฉูุงุณู ุงุณุชูุงุฏู ูโุดูุฏ.  

---

<div class="lesson-nav" style="display:flex; justify-content:space-between; margin-top:2em;">
  <a class="btn btn--inverse" href="{{ '/teaching/ai/mathmaticalnl' | relative_url }}">โฌ๏ธ ูุจู: ูุฏู ุฑุงุถ ููุฑูู </a>
  <a class="btn btn--primary" href="{{ '/teaching/ai/multi-class' | relative_url }}">ุจุนุฏ: ุทุจููโุจูุฏ ฺูุฏฺฉูุงุณู โก๏ธ</a>
</div>
